apply plugin: 'java'
sourceCompatibility = 1.7
version = '1.0'

repositories {
    maven {
        url "http://10.30.127.67:9091/artifactory/libs-release"
    }
}


configurations {
    sshAntTask
}
configurations {
    compile
}

dependencies {
    sshAntTask 'org.apache.ant:ant-jsch:1.9.4'
}

sourceSets {
    main {
        java.srcDir 'src'
    }
}

Properties properties = new Properties()
def buildProperty = project.projectDir.path + '/build.properties'
File propertiesFile = new File(buildProperty)
<<<<<<< HEAD
propertiesFile.withInputStream {
    properties.load(propertiesFile.newDataInputStream())
}
=======
	propertiesFile.withInputStream {
    		properties.load(propertiesFile.newDataInputStream())
}	
	
/**
*return project build jar file.
*/
def jarFiles = files {file(project.libsDir.path).listFiles() }
	
if(properties.remote == "true"){

	dependencies {
  			compile(group: 'engine', name: 'bhs', version: '1.0.7')
		}

	task(run, dependsOn: ['build']){ 

	def paramFilePath
	def xmlFilePath
	def xmlFileName
	def paramFileName
	def jarName;
	def clusterPass

		if (project.hasProperty("xmlpath")) {
			xmlFilePath=xmlpath
			xmlFileName =xmlpath.substring(xmlpath.lastIndexOf("/")+1);
			}
			if (project.hasProperty("paramFiles")) {
			paramFilePath=paramFiles
			paramFileName =paramFiles.substring(paramFiles.lastIndexOf("/")+1);
			}
			if (project.hasProperty("clusterPassword")) {
			clusterPass=clusterPassword
			}
		/**
		*Remote server hostname and credentials.
		**/

    	def user = properties.userName
    	def host = properties.host
    	def password = clusterPass
    	def runUtility=properties.runUtility
    	def jobXML=properties.jobXML
    	def lib=properties.libs
    	def paramFile=properties.paramFile
>>>>>>> Upgraded bhs engine jar version from 1.0.6 to 1.0.7

ext.cascadingVersion = '3.0.1'
ext.hadoopVersion = '2.6.0'
ext.hiveVersion = '1.2.0'

dependencies {
<<<<<<< HEAD
    compile(group: 'engine', name: 'bhs', version: '1.0.6')
    compile(group: 'cascading.avro', name: 'avro-scheme', version: '2.5.0')
    compile group: 'cascading', name: 'cascading-core', version: cascadingVersion
    compile group: 'cascading', name: 'cascading-hadoop2-mr1', version: cascadingVersion //required for plunger
    compile group: 'cascading', name: 'cascading-local', version: cascadingVersion //required for plunger
    compile group: 'org.apache.hadoop', name: 'hadoop-common', version: hadoopVersion //required for plunger
    compile group: 'org.apache.hadoop', name: 'hadoop-mapreduce-client-common', version: hadoopVersion
    compile group: 'cascading', name: 'cascading-hive', version: '2.0.0'
    compile(group: 'org.apache.hive', name: 'hive-exec', version: hiveVersion)
            {
                exclude group: 'com.google.guava'
                exclude group: 'org.apache.curator'
            }
    compile 'org.jgrapht:jgrapht-ext:0.9.1'
    compile(group: 'com.google.guava', name: 'guava', version: '14.0.1')
    compile(group: 'org.slf4j', name: 'slf4j-api', version: '1.7.2')
    compile(group: 'com.twitter', name: 'parquet-cascading', version: '1.6.0')
    compile(group: 'com.twitter', name: 'parquet-hadoop', version: '1.6.0')
    compile(group: 'com.twitter', name: 'parquet-column', version: '1.6.0')
    compile(group: 'org.fluttercode.datafactory', name: 'datafactory', version: '0.8')
    compile(group: 'org.hamcrest', name: 'hamcrest-core', version: '1.3')
    testCompile(group: 'junit', name: 'junit', version: '4.11')
    testCompile(group: 'com.hotels', name: 'plunger', version: '4.11')
    testCompile(group: 'org.mockito', name: 'mockito-core', version: '1.9.5')
    testCompile(group: 'commons-io', name: 'commons-io', version: '2.4')
=======
  	compile(group: 'engine', name: 'bhs', version: '1.0.7')
  	compile(group: 'cascading.avro', name: 'avro-scheme', version: '2.5.0')
  	compile group: 'cascading', name: 'cascading-core', version: cascadingVersion
  	compile group: 'cascading', name: 'cascading-hadoop2-mr1', version: cascadingVersion //required for plunger
  	compile group: 'cascading', name: 'cascading-local', version: cascadingVersion //required for plunger
  	compile group: 'org.apache.hadoop', name: 'hadoop-common', version: hadoopVersion //required for plunger
  	compile group: 'org.apache.hadoop', name: 'hadoop-mapreduce-client-common', version: hadoopVersion
  	compile group: 'cascading', name: 'cascading-hive', version: '2.0.0'
  	compile (group: 'org.apache.hive', name: 'hive-exec', version: hiveVersion) 
  	{exclude group: 'com.google.guava'
  	exclude group: 'org.apache.curator'
  	}
  	compile 'org.jgrapht:jgrapht-ext:0.9.1'
  	compile (group: 'com.google.guava', name: 'guava', version: '14.0.1')
  	compile (group: 'org.slf4j', name: 'slf4j-api', version: '1.7.2')  
  	compile (group: 'com.twitter', name: 'parquet-cascading', version: '1.6.0')
  	compile (group: 'com.twitter', name: 'parquet-hadoop', version: '1.6.0')
  	compile (group: 'com.twitter', name: 'parquet-column', version: '1.6.0')
  	compile (group: 'org.fluttercode.datafactory', name: 'datafactory', version: '0.8')
  	compile (group: 'org.hamcrest', name: 'hamcrest-core', version: '1.3')
  	testCompile(group: 'junit', name: 'junit', version: '4.11')
  	testCompile(group: 'com.hotels', name: 'plunger', version: '4.11')
  	testCompile (group: 'org.mockito', name: 'mockito-core', version: '1.9.5')
  	testCompile (group: 'commons-io', name: 'commons-io', version: '2.4')  
>>>>>>> Upgraded bhs engine jar version from 1.0.6 to 1.0.7
}

test {
    testLogging.showStandardStreams = true
}


task scpJarFiles(dependsOn: ['build']) {

    doLast {
        println 'Copying library files...'

        ant.taskdef(
                name: 'scp',
                classname: 'org.apache.tools.ant.taskdefs.optional.ssh.Scp',
                classpath: configurations.sshAntTask.asPath)

        def jarFile
        def jarName
        def jarFiles = files {
            file(project.libsDir.path).listFiles()
        }

        jarFiles.each {
            File file ->
                jarFile = file.absolutePath
                jarName = file.name
        }

        try {
            ant.scp(
                    file: jarFile,
                    todir: "${username}@${host}:" + properties.remoteLibDir,
                    password: password,
                    trust: true,
            )
       } catch (Exception gradleException) {
            println '#Gradle failed to execute task#'
       }


    }
}

scpJarFiles.onlyIf {
    project.hasProperty('host')
    project.hasProperty('username')
    project.hasProperty('password')
}

task scpJobXML() {
    doLast {
        ant.taskdef(
                name: 'scp',
                classname: 'org.apache.tools.ant.taskdefs.optional.ssh.Scp',
                classpath: configurations.sshAntTask.asPath)


        println 'Copying XML files...'

        try {

            ant.scp(
                    file: jobXML,
                    todir: "${username}@${host}:" + properties.remoteJobXMLDir,
                    password: password,
                    trust: true,
            )
        } catch (Exception gradleException) {
            println '#Gradle failed to execute task#'
        }
    }
}

scpJobXML.onlyIf {
    project.hasProperty('host')
    project.hasProperty('username')
    project.hasProperty('password')
    project.hasProperty('jobXML');
}

task scpParameterFile() {
    doLast {
        println 'Copying Parameter files...'
        ant.taskdef(
                name: 'scp',
                classname: 'org.apache.tools.ant.taskdefs.optional.ssh.Scp',
                classpath: configurations.sshAntTask.asPath)
        try {
            ant.scp(
                    file: parameterFile,
                    todir: "${username}@${host}:" + properties.remoteParameterFileDir,
                    password: password,
                    trust: true,
            )
        } catch (Exception gradleException) {
            println '#Gradle failed to execute task#'
        }

    }
}

scpParameterFile.onlyIf {
    project.hasProperty('host')
    project.hasProperty('username')
    project.hasProperty('password')
    project.hasProperty('parameterFile');
}


task executeRemoteJob() {
    doLast {
        ant.taskdef(
                name: 'sshexec',
                classname: 'org.apache.tools.ant.taskdefs.optional.ssh.SSHExec',
                classpath: configurations.sshAntTask.asPath)

        println "Executing remote job..."

        def jarFile
        def jarName
        def jarFiles = files {
            file(project.libsDir.path).listFiles()
        }

        jarFiles.each {
            File file ->
                jarFile = file.absolutePath
                jarName = file.name
        }


        def xmlFileName = jobXML.substring(jobXML.lastIndexOf("/") + 1);
        def parameterFileName = parameterFile.substring(parameterFile.lastIndexOf("/") + 1);


        println 'executing command - ' + properties.runUtility + " -xmlpath " + properties.remoteJobXMLDir + "/" + xmlFileName + " -libjars " + properties.remoteLibDir + "/" + jarName + " -paramfiles " + properties.remoteParameterFileDir + "/" + parameterFileName

        try {
            ant.sshexec(
                    host: host,
                    username: username,
                    password: password,
                    trust: true,
                    command: properties.runUtility + " -xmlpath " + properties.remoteJobXMLDir + "/" + xmlFileName + " -libjars " + properties.remoteLibDir + "/" + jarName + " -paramfiles " + properties.remoteParameterFileDir + "/" + parameterFileName
            )
        } catch (Exception gradleException) {
            println '#Gradle failed to execute task#'
        }

    }
}

executeRemoteJob.onlyIf {
    project.hasProperty('host')
    project.hasProperty('username')
    project.hasProperty('password')
    project.hasProperty('jobXML')
    project.hasProperty('parameterFile');
}

task executeLocalJob(dependsOn: ['build', 'classes'], type: JavaExec) {

	if(project.hasProperty('localjob')){
		def mainClassName = 'com.bitwiseglobal.commandline.utilities.BHSExecution'
    def transformFiles = files { file(project.libsDir.path).listFiles() }

	println 'Executing local job'
    main = mainClassName
    standardOutput = System.out
    errorOutput = System.err
    classpath += transformFiles + configurations.compile
    def argsArray = getArgsForRunJob()
    args = ['' + argsArray[0] + '', '' + argsArray[1] + '', '' + argsArray[2] + '', '' + argsArray[3] + '']
		
	}
}

def getArgsForRunJob() {
    def argsArray = new String[4]
    if (project.hasProperty("jobXML")) {
        argsArray[0] = "-xmlpath"
        argsArray[1] = jobXML
    }
    if (project.hasProperty("parameterFile")) {
        argsArray[2] = "-paramFiles"
        argsArray[3] = parameterFile
    }
    return argsArray
}

executeLocalJob.onlyIf {
    project.hasProperty('jobXML')
    project.hasProperty('parameterFile')
    project.hasProperty('localjob');
}

task killRemoteJob() << {
	
	if(jobprocessid !=null){
		println "Gradle is Killing remote job"
    ant.taskdef(
            name: 'sshexec',
            classname: 'org.apache.tools.ant.taskdefs.optional.ssh.SSHExec',
            classpath: configurations.sshAntTask.asPath)

    ant.sshexec(
            host: host,
            username: username,
            password: password,
            trust: true,
            command: "sh /home/hduser/milestone/kill_job.sh " + jobprocessid)
      }
    
}

killRemoteJob.onlyIf {
    project.hasProperty('host')
    project.hasProperty('username')
    project.hasProperty('password')
    project.hasProperty('jobprocessid');
}
